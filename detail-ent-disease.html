<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ENT Disease Classification with ViT - Detail</title>
    <link href="dist/output.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css">
</head>
<body class="bg-white dark:bg-slate-900 transition-colors duration-300">
    <header class="bg-transparent absolute top-0 left-0 w-full flex items-center z-10">
        <div class="container">
            <div class="flex items-center justify-between relative">
                <div class="px-4">
                    <a href="index.html" class="block py-6 font-bold text-lg md:text-2xl text-dark dark:text-white">
                        MyPortfolio<span class="text-indigo-600 dark:text-indigo-400 text-2xl">+</span>
                    </a>
                </div>
                <div class="flex items-center gap-4 px-4">
                    <!-- Dark Mode Toggle -->
                    <button id="theme-toggle" class="p-2 rounded-lg hover:bg-slate-100 dark:hover:bg-slate-800 transition-colors">
                        <svg id="theme-toggle-dark-icon" class="hidden w-5 h-5 text-slate-700 dark:text-slate-300" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
                            <path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"></path>
                        </svg>
                        <svg id="theme-toggle-light-icon" class="hidden w-5 h-5 text-slate-700 dark:text-slate-300" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
                            <path d="M10 2a1 1 0 011 1v1a1 1 0 11-2 0V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95l.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707a1 1 0 11-1.414-1.414l.707-.707a1 1 0 011.414 0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707a1 1 0 00-1.414 1.414l.707.707zm1.414 8.486l-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"></path>
                        </svg>
                    </button>
                    
                    <a href="index.html#portfolio" class="text-dark dark:text-white hover:text-indigo-600 dark:hover:text-indigo-400 transition-colors">
                        <i class="fas fa-arrow-left mr-2"></i>Back to Portfolio
                    </a>
                </div>
            </div>
        </div>
    </header>

    <!-- Hero Section -->
    <section class="pt-28 pb-16 bg-slate-50 dark:bg-slate-900 relative overflow-hidden">
        <div class="container max-w-6xl mx-auto px-4 relative z-10">
            <div class="grid lg:grid-cols-2 gap-8 items-center">
                <!-- Left Content -->
                <div>
                    <div class="mb-6">
                        <span class="inline-flex items-center gap-2 px-5 py-2.5 bg-indigo-600 text-white text-sm font-bold rounded-full shadow-lg">
                            <i class="fas fa-briefcase"></i>
                            REAL WORLD PROJECT
                        </span>
                    </div>
                    <h1 class="text-4xl md:text-5xl lg:text-6xl font-extrabold mb-6 text-slate-900 dark:text-white">
                        ENT Disease Classification with Vision Transformer
                    </h1>
                    <p class="text-lg md:text-xl text-slate-600 dark:text-slate-300 leading-relaxed mb-8">
                        Automated ENT disease classification system using Vision Transformer (ViT-base) achieving ~86% accuracy across 12 disease classes, improving 10% over previous DenseNet169 implementation.
                    </p>
                    
                    <!-- Technology Tags -->
                    <div class="flex flex-wrap gap-3 mb-8">
                        <span class="px-4 py-2.5 bg-white dark:bg-slate-800 border border-slate-200 dark:border-slate-700 text-slate-700 dark:text-slate-300 rounded-lg text-sm font-semibold shadow-sm hover:shadow-md transition-all">
                            <i class="fas fa-stethoscope mr-2 text-indigo-600"></i>Medical AI
                        </span>
                        <span class="px-4 py-2.5 bg-white dark:bg-slate-800 border border-slate-200 dark:border-slate-700 text-slate-700 dark:text-slate-300 rounded-lg text-sm font-semibold shadow-sm hover:shadow-md transition-all">
                            <i class="fas fa-project-diagram mr-2 text-indigo-600"></i>Transformer
                        </span>
                        <span class="px-4 py-2.5 bg-white dark:bg-slate-800 border border-slate-200 dark:border-slate-700 text-slate-700 dark:text-slate-300 rounded-lg text-sm font-semibold shadow-sm hover:shadow-md transition-all">
                            <i class="fas fa-chart-line mr-2 text-indigo-600"></i>86% Accuracy
                        </span>
                    </div>

                    <!-- Key Metrics -->
                    <div class="grid grid-cols-3 gap-4">
                        <div class="bg-white dark:bg-slate-800 rounded-xl p-4 border border-slate-200 dark:border-slate-700 shadow-sm">
                            <div class="text-2xl font-bold text-indigo-600 dark:text-indigo-400">86%</div>
                            <div class="text-xs text-slate-600 dark:text-slate-400 mt-1">Accuracy</div>
                        </div>
                        <div class="bg-white dark:bg-slate-800 rounded-xl p-4 border border-slate-200 dark:border-slate-700 shadow-sm">
                            <div class="text-2xl font-bold text-indigo-600 dark:text-indigo-400">87%</div>
                            <div class="text-xs text-slate-600 dark:text-slate-400 mt-1">F1-Score</div>
                        </div>
                        <div class="bg-white dark:bg-slate-800 rounded-xl p-4 border border-slate-200 dark:border-slate-700 shadow-sm">
                            <div class="text-2xl font-bold text-indigo-600 dark:text-indigo-400">12</div>
                            <div class="text-xs text-slate-600 dark:text-slate-400 mt-1">Classes</div>
                        </div>
                    </div>
                </div>

                <!-- Right Visual -->
                <div class="relative">
                    <div class="relative bg-white dark:bg-slate-800 rounded-3xl p-8 border border-slate-200 dark:border-slate-700 shadow-xl">
                        <div class="relative space-y-4">
                            <div class="flex items-center gap-3 bg-slate-50 dark:bg-slate-700 rounded-xl p-4 border border-slate-200 dark:border-slate-600">
                                <div class="w-12 h-12 bg-indigo-600 rounded-lg flex items-center justify-center flex-shrink-0">
                                    <i class="fas fa-eye text-white text-xl"></i>
                                </div>
                                <div class="flex-1">
                                    <div class="font-semibold text-slate-800 dark:text-slate-200">Vision Transformer</div>
                                    <div class="text-sm text-slate-600 dark:text-slate-400">ViT-base architecture</div>
                                </div>
                            </div>
                            
                            <div class="flex items-center gap-3 bg-slate-50 dark:bg-slate-700 rounded-xl p-4 border border-slate-200 dark:border-slate-600">
                                <div class="w-12 h-12 bg-indigo-600 rounded-lg flex items-center justify-center flex-shrink-0">
                                    <i class="fas fa-brain text-white text-xl"></i>
                                </div>
                                <div class="flex-1">
                                    <div class="font-semibold text-slate-800 dark:text-slate-200">Deep Learning</div>
                                    <div class="text-sm text-slate-600 dark:text-slate-400">12 disease classification</div>
                                </div>
                            </div>
                            
                            <div class="flex items-center gap-3 bg-slate-50 dark:bg-slate-700 rounded-xl p-4 border border-slate-200 dark:border-slate-600">
                                <div class="w-12 h-12 bg-indigo-600 rounded-lg flex items-center justify-center flex-shrink-0">
                                    <i class="fas fa-chart-line text-white text-xl"></i>
                                </div>
                                <div class="flex-1">
                                    <div class="font-semibold text-slate-800 dark:text-slate-200">High Performance</div>
                                    <div class="text-sm text-slate-600 dark:text-slate-400">10% improvement</div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Hero Image Banner -->
    <section class="py-0 -mt-8">
        <div class="container max-w-6xl mx-auto px-4">
            <div class="relative overflow-hidden rounded-3xl shadow-xl border border-slate-200 dark:border-slate-700">
                <img src="dist/img/portfolio/7.png" alt="ENT Disease Classification" class="w-full h-[400px] object-cover">
                <div class="absolute inset-0 bg-gradient-to-t from-black/60 via-transparent to-transparent"></div>
            </div>
        </div>
    </section>

    <!-- Content Section -->
    <section class="py-16 min-h-screen">
        <div class="container max-w-5xl mx-auto px-4">

            <div class="prose prose-lg dark:prose-invert max-w-none">
                <h2>Overview</h2>
                <p>This project implements an automated classification system for ENT (Ear, Nose, Throat) diseases using deep learning. The current focus is on ear disease classification with 12 different conditions including Normal, Cerumen, OMA (Otitis Media Akut) variants, OMed (Otitis Media) types, Otomikosis, and OE Difusa.</p>

                <h2>Performance Metrics</h2>
                <table class="min-w-full border border-slate-300 dark:border-slate-700">
                    <tbody>
                        <tr><td class="border px-4 py-2">Test Accuracy</td><td class="border px-4 py-2">~86.1%</td></tr>
                        <tr><td class="border px-4 py-2">Macro F1-Score</td><td class="border px-4 py-2">~87.3%</td></tr>
                        <tr><td class="border px-4 py-2">Weighted F1-Score</td><td class="border px-4 py-2">~86.9%</td></tr>
                    </tbody>
                </table>

                <h3>Improvements Over Previous Model</h3>
                <table class="min-w-full border border-slate-300 dark:border-slate-700">
                    <thead>
                        <tr>
                            <th class="border px-4 py-2">Model</th>
                            <th class="border px-4 py-2">Accuracy</th>
                            <th class="border px-4 py-2">Parameters</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td class="border px-4 py-2">DenseNet169 (previous)</td><td class="border px-4 py-2">~76%</td><td class="border px-4 py-2">14.15M</td></tr>
                        <tr><td class="border px-4 py-2">ViT-base (current)</td><td class="border px-4 py-2">~86%</td><td class="border px-4 py-2">86.4M</td></tr>
                    </tbody>
                </table>

                <h2>Dataset</h2>
                <p>The dataset consists of 823 ear endoscopy images organized into 12 categories covering conditions from normal ear to various types of Otitis Media and fungal infections. The data is split 80% training and 20% testing with stratified distribution to maintain class balance.</p>
                <div class="my-8">
                    <img src="dist/img/projects/ent-disease/distribution-v0.1.png" alt="Class Distribution" class="w-full rounded-lg shadow-lg border border-slate-200 dark:border-slate-700">
                </div>

                <h3>Disease Categories</h3>
                <ul>
                    <li><strong>Cerumen:</strong> Earwax buildup</li>
                    <li><strong>Normal:</strong> Healthy ear</li>
                    <li><strong>OE Difusa:</strong> Diffuse Otitis Externa</li>
                    <li><strong>OMA Variants:</strong> Acute Otitis Media (Hyperemic, Tubal Occlusion, Perforation, Suppuration)</li>
                    <li><strong>OMed Efusi:</strong> Otitis Media with Effusion</li>
                    <li><strong>OMedK Types:</strong> Chronic Otitis Media (Resolution, Safe Type, Dangerous Type)</li>
                    <li><strong>Otomikosis:</strong> Fungal ear infection</li>
                </ul>

                <h2>Model Architecture</h2>
                <div class="my-8">
                    <img src="dist/img/projects/ent-disease/vit-architechture.png" alt="ViT Architecture" class="w-full rounded-lg shadow-lg border border-slate-200 dark:border-slate-700">
                </div>
                <ul>
                    <li><strong>Vision Transformer (ViT):</strong> google/vit-base-patch16-224-in21k</li>
                    <li><strong>Transfer Learning:</strong> Pre-trained on ImageNet-21k, fine-tuned on ear disease dataset</li>
                    <li><strong>Input Size:</strong> 224×224 RGB images</li>
                    <li><strong>Output:</strong> 12 disease classes with confidence scores</li>
                </ul>

                <h2>Training Configuration</h2>
                <ul>
                    <li>Learning Rate: 2e-5</li>
                    <li>Batch Size: 8 (per device)</li>
                    <li>Epochs: 30</li>
                    <li>Optimizer: Adam with weight decay (0.01)</li>
                    <li>Strategy: Load best model based on accuracy</li>
                </ul>

                <h3>Data Augmentation</h3>
                <ul>
                    <li>Random resized crop (224×224)</li>
                    <li>Random horizontal flip</li>
                    <li>Normalization (mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])</li>
                </ul>

                <h2>Evaluation Results</h2>
                <p>The model shows strong performance across most classes with minimal overfitting due to effective data augmentation. Training and validation loss converge smoothly, with validation accuracy plateauing around epoch 15-20.</p>

                <h3>Training History</h3>
                <div class="my-8">
                    <img src="dist/img/projects/ent-disease/logs-v0.1.png" alt="Training History" class="w-full rounded-lg shadow-lg border border-slate-200 dark:border-slate-700">
                </div>

                <h3>Confusion Matrix</h3>
                <div class="my-8">
                    <img src="dist/img/projects/ent-disease/confusion-matrix-v0.1.png" alt="Confusion Matrix" class="w-full rounded-lg shadow-lg border border-slate-200 dark:border-slate-700">
                </div>

                <h3>Classification Report</h3>
                <div class="my-8">
                    <img src="dist/img/projects/ent-disease/classification-report-v0.1.png" alt="Classification Report" class="w-full rounded-lg shadow-lg border border-slate-200 dark:border-slate-700">
                </div>

                <h3>Per-Class Performance</h3>
                <ul>
                    <li><strong>Best performing:</strong> Normal, Cerumen, OMedResolusi (>90% F1)</li>
                    <li><strong>Moderate performance:</strong> OMA variants (80-90% F1)</li>
                    <li><strong>Challenging:</strong> OMedK subtypes requiring expert-level distinction</li>
                </ul>

                <h3>Attention Rollout Visualization</h3>
                <p>Attention Rollout visualizes where the Vision Transformer focuses when making predictions. Unlike Grad-CAM (designed for CNNs), it uses the transformer's native attention weights across all layers to show which image regions contribute most to classification decisions, highlighting the model's ability to focus on clinically relevant areas.</p>
                <div class="my-8">
                    <img src="dist/img/projects/ent-disease/attention-rollout.png" alt="Attention Rollout" class="w-full rounded-lg shadow-lg border border-slate-200 dark:border-slate-700">
                </div>

                <h2>Production Deployment</h2>
                <p>The trained model is deployed as a RESTful API using Docker, FastAPI, and Uvicorn for real-time inference.</p>
                <div class="my-8">
                    <img src="dist/img/projects/ent-disease/deployment-architecture.png" alt="Deployment Architecture" class="w-full rounded-lg shadow-lg border border-slate-200 dark:border-slate-700">
                </div>

                <h3>Performance</h3>
                <ul>
                    <li>Inference time (CPU): ~200-300ms per image (11th Gen Intel® Core™ i5-11400H × 12)</li>
                    <li>Memory usage: ~1.2GB (model loaded in memory)</li>
                </ul>

                <h3>Technologies</h3>
                <ul>
                    <li>Docker</li>
                    <li>FastAPI</li>
                    <li>Uvicorn</li>
                </ul>

                <h2>Limitations & Challenges</h2>
                <ul>
                    <li><strong>Dataset Size:</strong> Limited training samples for some rare disease categories</li>
                    <li><strong>Image Quality:</strong> Variability in lighting conditions, artifacts, and motion blur</li>
                    <li><strong>Expert-Level Distinctions:</strong> Some disease subtypes require years of clinical experience to distinguish accurately</li>
                </ul>

                <h2>Future Work</h2>
                <ul>
                    <li>Experiment with smaller ViT variants (ViT-small, ViT-tiny)</li>
                    <li>Knowledge distillation to compress model</li>
                    <li>Quantization for edge deployment</li>
                    <li>Implement uncertainty-based active learning</li>
                    <li>Enhanced explainability for clinical decision support</li>
                </ul>
            </div>
        </div>
    </section>

    <footer class="bg-slate-900 dark:bg-slate-950 pt-12 pb-6">
        <div class="container text-center">
            <p class="text-slate-400">©2023 Maulana Surya Negara. All rights reserved.</p>
        </div>
    </footer>

    <script src="dist/js/script.js"></script>
</body>
</html>
