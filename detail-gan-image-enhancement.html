<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pix2Pix GAN Image Enhancement - Detail</title>
    <link href="dist/output.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css">
</head>
<body class="bg-white dark:bg-slate-900 transition-colors duration-300">
    <header class="bg-transparent absolute top-0 left-0 w-full flex items-center z-10">
        <div class="container">
            <div class="flex items-center justify-between relative">
                <div class="px-4">
                    <a href="index.html" class="block py-6 font-bold text-lg md:text-2xl text-dark dark:text-white">
                        MyPortfolio<span class="text-indigo-600 dark:text-indigo-400 text-2xl">+</span>
                    </a>
                </div>
                <div class="flex items-center gap-4 px-4">
                    <!-- Dark Mode Toggle -->
                    <button id="theme-toggle" class="p-2 rounded-lg hover:bg-slate-100 dark:hover:bg-slate-800 transition-colors">
                        <svg id="theme-toggle-dark-icon" class="hidden w-5 h-5 text-slate-700 dark:text-slate-300" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
                            <path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"></path>
                        </svg>
                        <svg id="theme-toggle-light-icon" class="hidden w-5 h-5 text-slate-700 dark:text-slate-300" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
                            <path d="M10 2a1 1 0 011 1v1a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95l.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707a1 1 0 11-1.414-1.414l.707-.707a1 1 0 011.414 0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707a1 1 0 00-1.414 1.414l.707.707zm1.414 8.486l-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"></path>
                        </svg>
                    </button>
                    
                    <a href="index.html#portfolio" class="text-dark dark:text-white hover:text-indigo-600 dark:hover:text-indigo-400 transition-colors">
                        <i class="fas fa-arrow-left mr-2"></i>Back to Portfolio
                    </a>
                </div>
            </div>
        </div>
    </header>

    <!-- Hero Section -->
    <section class="pt-28 pb-16 bg-slate-50 dark:bg-slate-900 relative overflow-hidden">
        <div class="container max-w-6xl mx-auto px-4 relative z-10">
            <div class="grid lg:grid-cols-2 gap-8 items-center">
                <!-- Left Content -->
                <div>
                    <div class="mb-6">
                        <span class="inline-flex items-center gap-2 px-5 py-2.5 bg-indigo-600 text-white text-sm font-bold rounded-full shadow-lg">
                            <i class="fas fa-briefcase"></i>
                            REAL WORLD PROJECT
                        </span>
                    </div>
                    <h1 class="text-4xl md:text-5xl lg:text-6xl font-extrabold mb-6 text-slate-900 dark:text-white">
                        Pix2Pix GAN for Endoscopic Image Enhancement
                    </h1>
                    <p class="text-lg md:text-xl text-slate-600 dark:text-slate-300 leading-relaxed mb-8">
                        Advanced image enhancement model using Attention U-Net generator and PatchGAN discriminator for endoscopic image quality improvement, achieving PSNR of 26dB and SSIM of 0.80.
                    </p>
                    
                    <!-- Technology Tags -->
                    <div class="flex flex-wrap gap-3 mb-8">
                        <span class="px-4 py-2.5 bg-white dark:bg-slate-800 border border-slate-200 dark:border-slate-700 text-slate-700 dark:text-slate-300 rounded-lg text-sm font-semibold shadow-sm hover:shadow-md transition-all">
                            <i class="fas fa-magic mr-2 text-indigo-600"></i>GAN
                        </span>
                        <span class="px-4 py-2.5 bg-white dark:bg-slate-800 border border-slate-200 dark:border-slate-700 text-slate-700 dark:text-slate-300 rounded-lg text-sm font-semibold shadow-sm hover:shadow-md transition-all">
                            <i class="fas fa-image mr-2 text-indigo-600"></i>Enhancement
                        </span>
                        <span class="px-4 py-2.5 bg-white dark:bg-slate-800 border border-slate-200 dark:border-slate-700 text-slate-700 dark:text-slate-300 rounded-lg text-sm font-semibold shadow-sm hover:shadow-md transition-all">
                            <i class="fas fa-microscope mr-2 text-indigo-600"></i>Medical Imaging
                        </span>
                    </div>

                    <!-- Key Metrics -->
                    <div class="grid grid-cols-3 gap-4">
                        <div class="bg-white dark:bg-slate-800 rounded-xl p-4 border border-slate-200 dark:border-slate-700 shadow-sm">
                            <div class="text-2xl font-bold text-indigo-600 dark:text-indigo-400">26dB</div>
                            <div class="text-xs text-slate-600 dark:text-slate-400 mt-1">PSNR</div>
                        </div>
                        <div class="bg-white dark:bg-slate-800 rounded-xl p-4 border border-slate-200 dark:border-slate-700 shadow-sm">
                            <div class="text-2xl font-bold text-indigo-600 dark:text-indigo-400">0.80</div>
                            <div class="text-xs text-slate-600 dark:text-slate-400 mt-1">SSIM</div>
                        </div>
                        <div class="bg-white dark:bg-slate-800 rounded-xl p-4 border border-slate-200 dark:border-slate-700 shadow-sm">
                            <div class="text-2xl font-bold text-indigo-600 dark:text-indigo-400">Pix2Pix</div>
                            <div class="text-xs text-slate-600 dark:text-slate-400 mt-1">Model</div>
                        </div>
                    </div>
                </div>

                <!-- Right Visual -->
                <div class="relative">
                    <div class="relative bg-white dark:bg-slate-800 rounded-3xl p-8 border border-slate-200 dark:border-slate-700 shadow-xl">
                        <div class="relative space-y-4">
                            <div class="flex items-center gap-3 bg-slate-50 dark:bg-slate-700 rounded-xl p-4 border border-slate-200 dark:border-slate-600">
                                <div class="w-12 h-12 bg-indigo-600 rounded-lg flex items-center justify-center flex-shrink-0">
                                    <i class="fas fa-network-wired text-white text-xl"></i>
                                </div>
                                <div class="flex-1">
                                    <div class="font-semibold text-slate-800 dark:text-slate-200">Attention U-Net</div>
                                    <div class="text-sm text-slate-600 dark:text-slate-400">Generator architecture</div>
                                </div>
                            </div>
                            
                            <div class="flex items-center gap-3 bg-slate-50 dark:bg-slate-700 rounded-xl p-4 border border-slate-200 dark:border-slate-600">
                                <div class="w-12 h-12 bg-indigo-600 rounded-lg flex items-center justify-center flex-shrink-0">
                                    <i class="fas fa-bolt text-white text-xl"></i>
                                </div>
                                <div class="flex-1">
                                    <div class="font-semibold text-slate-800 dark:text-slate-200">PatchGAN</div>
                                    <div class="text-sm text-slate-600 dark:text-slate-400">Discriminator network</div>
                                </div>
                            </div>
                            
                            <div class="flex items-center gap-3 bg-slate-50 dark:bg-slate-700 rounded-xl p-4 border border-slate-200 dark:border-slate-600">
                                <div class="w-12 h-12 bg-indigo-600 rounded-lg flex items-center justify-center flex-shrink-0">
                                    <i class="fas fa-chart-line text-white text-xl"></i>
                                </div>
                                <div class="flex-1">
                                    <div class="font-semibold text-slate-800 dark:text-slate-200">High Quality</div>
                                    <div class="text-sm text-slate-600 dark:text-slate-400">Enhanced images</div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Hero Image Banner -->
    <section class="py-0 -mt-8">
        <div class="container max-w-6xl mx-auto px-4">
            <div class="relative overflow-hidden rounded-3xl shadow-xl border border-slate-200 dark:border-slate-700">
                <img src="dist/img/portfolio/2.png" alt="GAN Image Enhancement" class="w-full h-[400px] object-cover">
                <div class="absolute inset-0 bg-gradient-to-t from-black/60 via-transparent to-transparent"></div>
            </div>
        </div>
    </section>

    <!-- Content Section -->
    <section class="py-16 min-h-screen">
        <div class="container max-w-5xl mx-auto px-4">

            <div class="prose prose-lg dark:prose-invert max-w-none">
                <h2>Overview</h2>
                <p>This project implements a Pix2Pix GAN-based system for enhancing low-quality endoscopic images of ENT (Ear, Nose, Throat) organs. The system takes low-quality endoscopic images as input and generates high-quality enhanced versions, improving visibility for better clinical diagnosis.</p>

                <h2>Performance Metrics</h2>
                <table class="min-w-full border border-slate-300 dark:border-slate-700">
                    <tbody>
                        <tr><td class="border px-4 py-2">PSNR</td><td class="border px-4 py-2">~26dB</td></tr>
                        <tr><td class="border px-4 py-2">SSIM</td><td class="border px-4 py-2">~0.80</td></tr>
                    </tbody>
                </table>

                <h2>Model Architecture</h2>
                <table class="min-w-full border border-slate-300 dark:border-slate-700">
                    <tbody>
                        <tr><td class="border px-4 py-2">Generator</td><td class="border px-4 py-2">UNet with Attention (SR)</td></tr>
                        <tr><td class="border px-4 py-2">Discriminator</td><td class="border px-4 py-2">PatchGAN</td></tr>
                        <tr><td class="border px-4 py-2">Input Size</td><td class="border px-4 py-2">256×256 RGB (LQ)</td></tr>
                        <tr><td class="border px-4 py-2">Output Size</td><td class="border px-4 py-2">512×512 RGB (HQ)</td></tr>
                        <tr><td class="border px-4 py-2">Generator Params</td><td class="border px-4 py-2">~8M</td></tr>
                        <tr><td class="border px-4 py-2">Discriminator Params</td><td class="border px-4 py-2">~2M</td></tr>
                    </tbody>
                </table>

                <h3>Key Features</h3>
                <ul>
                    <li>Attention mechanism for better feature focus</li>
                    <li>Hinge loss for stable training</li>
                    <li>Multi-GPU support with MirroredStrategy</li>
                    <li>ONNX export for efficient inference</li>
                </ul>

                <h2>Dataset</h2>
                <p>The dataset consists of high-quality endoscopic images that are synthetically degraded to create training pairs. HQ images serve as ground truth while degraded images are used as input for training.</p>

                <h3>Categories</h3>
                <ul>
                    <li><strong>Ear:</strong> Cerumen, Normal, OE Difusa, OMA variants, OMed types, Otomikosis</li>
                    <li><strong>Nose:</strong> Normal, Polip nasi, Rinitis variants, Septum deviasi, Sinusitis types, Tumor cavum</li>
                    <li><strong>Throat:</strong> Normal, Laringitis kronis, Pharyngitis variants, Tonsilitis types</li>
                </ul>

                <h3>Data Split</h3>
                <ul>
                    <li>Training: 80% (synthetic degraded pairs)</li>
                    <li>Validation: 20%</li>
                    <li>Total HQ images: ~800+ per category</li>
                </ul>

                <h3>Degradation Pipeline</h3>
                <p>Synthetic degradation includes:</p>
                <ul>
                    <li>Resize jitter with random scaling</li>
                    <li>Multiple blur effects (Gaussian, Box, Motion)</li>
                    <li>Exposure & gamma adjustments</li>
                    <li>Color corrections (contrast, saturation, white balance)</li>
                    <li>Lighting artifacts (vignetting, banding)</li>
                    <li>Optical aberrations (chromatic aberration, specular glare)</li>
                    <li>Noise injection (shot noise, read noise)</li>
                    <li>JPEG compression artifacts</li>
                </ul>

                <h2>Training Configuration</h2>
                <ul>
                    <li>Batch Size: 8</li>
                    <li>Learning Rate: 2e-4 (both Generator and Discriminator)</li>
                    <li>Epochs: 100+</li>
                    <li>Optimizer: Adam</li>
                    <li>Multi-GPU: MirroredStrategy</li>
                    <li>Image Sizes: LR=256, HR=512</li>
                </ul>

                <h3>Loss Functions</h3>
                <ul>
                    <li>Hinge loss for adversarial training</li>
                    <li>Perceptual loss (VGG-based)</li>
                    <li>L1 reconstruction loss</li>
                </ul>

                <h3>Data Augmentation</h3>
                <ul>
                    <li>Random rotations (90°, 180°, 270°)</li>
                    <li>Random crops (90% of original)</li>
                    <li>Bicubic downscaling</li>
                    <li>Synthetic degradation (blur, noise, compression)</li>
                </ul>

                <h2>Evaluation Results</h2>
                <p>The model converges steadily with adversarial training, showing improved PSNR and SSIM over epochs. The attention mechanism helps focus on clinically relevant regions.</p>

                <h3>Visual Results</h3>
                <div class="my-8">
                    <img src="dist/img/projects/gan-enhancement/sample.png" alt="Image Enhancement Sample" class="w-full rounded-lg shadow-lg border border-slate-200 dark:border-slate-700">
                </div>
                <p>The enhanced images show:</p>
                <ul>
                    <li>Reduced motion blur</li>
                    <li>Improved contrast and sharpness</li>
                    <li>Better visibility of anatomical structures</li>
                    <li>Maintained color fidelity</li>
                </ul>

                <h2>Production Deployment</h2>
                <p>The trained model is deployed as a RESTful API using Docker, FastAPI, and ONNX Runtime for real-time inference.</p>

                <h3>Performance</h3>
                <ul>
                    <li>Inference time (CPU): ~100-200ms per image</li>
                    <li>Memory usage: ~2GB (ONNX model)</li>
                    <li>Input: 256×256 image</li>
                    <li>Output: 512×512 enhanced image</li>
                </ul>

                <h3>Technologies</h3>
                <ul>
                    <li>Docker</li>
                    <li>FastAPI</li>
                    <li>ONNX Runtime</li>
                    <li>Uvicorn</li>
                </ul>

                <h2>Limitations & Challenges</h2>
                <ul>
                    <li><strong>Dataset Quality:</strong> Limited real paired LQ-HQ images, synthetic degradation may not capture all real-world artifacts</li>
                    <li><strong>Computational Requirements:</strong> High memory usage during training</li>
                    <li><strong>Generalization:</strong> Trained on specific ENT datasets, performance varies with input quality</li>
                </ul>

                <h2>Future Work</h2>
                <ul>
                    <li>Lightweight architectures (MobileNet, EfficientNet)</li>
                    <li>Quantization for mobile deployment</li>
                    <li>Separate enhancement models for each ENT organ</li>
                    <li>Manual degradation calculations for more realistic LQ simulation</li>
                    <li>Integration with existing medical imaging systems</li>
                    <li>Real-time video enhancement</li>
                </ul>
            </div>
        </div>
    </section>

    <footer class="bg-slate-900 dark:bg-slate-950 pt-12 pb-6">
        <div class="container text-center">
            <p class="text-slate-400">©2023 Maulana Surya Negara. All rights reserved.</p>
        </div>
    </footer>

    <script src="dist/js/script.js"></script>
</body>
</html>
